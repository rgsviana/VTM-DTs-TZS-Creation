# -*- coding: utf-8 -*-
"""Treino_DT_TZS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y9y8UQmAiMY-O9Wz5lsEmPeG2E2lsHk4

TAMANHO DA CU PARA CRIAR A SUA ÁRVORE DE DECISÃO
"""

cu_eixo_x = 128
cu_eixo_y = 128

"""HIPERPARAMETROS PARA ESTA CU"""

hiper_criterion = 'entropy'
hiper_min_samples_split = 225
hiper_min_samples_leaf = 40
hiper_max_features = 25
hiper_max_depth = 83
hiper_max_leaf_nodes = 230

"""PREPARAÇÃO DOS ARQUIVOS"""

!pip install scikit-learn

from google.colab import drive
drive.mount('/content/drive')

"""DATASET TESTE"""

!ls 'drive/My Drive/Mestrado/Dissertação/Treinamento DTs TZS/VTM 16.2 - Dataset Teste'

import glob
lista = glob.glob ('drive/My Drive/Mestrado/Dissertação/Treinamento DTs TZS/VTM 16.2 - Dataset Teste/*.csv')

labels = ["qp",	"depth",	"qt_depht",	"mt_depth",	"video_width",	"video_heigh",	"cu_pos_x",	"cu_pos_y",	"cu_width",	"cu_height",	"bcw_index",	"imv",	"mv_uni_l0_hor_x",	"mv_uni_l0_ver_y",	"mv_uni_l1_hor_x",	"mv_uni_l1_ver_y",	"cost_mv_uni_l0",	"cost_mv_uni_l1",	"bits_mv_uni_l0",	"bits_mv_uni_l1",	"mv_bi_l0_hor_x",	"mv_bi_l0_ver_y",	"mv_bi_l1_hor_x",	"mv_bi_l1_ver_y",	"cost_bi",	"bits_mv_bi",	"smvd",	"inter_dir_normal",	"atual_QP",	"rui_SAD",	"cStruct_iBestX",	"cStruct_iBestY",	"executaTZS"]

blocksize = [cu_eixo_x, cu_eixo_y]

import pandas as pd
import gc
dataframe_teste = pd.DataFrame()
for csv in lista:
  print (csv)
  d = pd.read_csv (csv, sep=";", nrows=1000000)
  d.drop(columns=["inter_dir_normal"])
  d = d[d["cu_width"] == blocksize[0]]
  d = d[d["cu_height"] == blocksize[1]]

  n_linhas = len(d)
  if n_linhas > 10000:
    n_linhas_remover = n_linhas - 10000
    linhas_remover = d.sample(n=n_linhas_remover).index
    d = d.drop(linhas_remover)


  dataframe_teste = pd.concat([dataframe_teste, d], axis=0)
  del d
  gc.collect()

dataframe_teste

"""DATASET TREINO"""

!ls 'drive/My Drive/Mestrado/Dissertação/Treinamento DTs TZS/VTM 16.2 - Dataset Treino'

import glob
lista = glob.glob ('drive/My Drive/Mestrado/Dissertação/Treinamento DTs TZS/VTM 16.2 - Dataset Treino/*.csv')

labels = ["qp",	"depth",	"qt_depht",	"mt_depth",	"video_width",	"video_heigh",	"cu_pos_x",	"cu_pos_y",	"cu_width",	"cu_height",	"bcw_index",	"imv",	"mv_uni_l0_hor_x",	"mv_uni_l0_ver_y",	"mv_uni_l1_hor_x",	"mv_uni_l1_ver_y",	"cost_mv_uni_l0",	"cost_mv_uni_l1",	"bits_mv_uni_l0",	"bits_mv_uni_l1",	"mv_bi_l0_hor_x",	"mv_bi_l0_ver_y",	"mv_bi_l1_hor_x",	"mv_bi_l1_ver_y",	"cost_bi",	"bits_mv_bi",	"smvd",	"inter_dir_normal",	"atual_QP",	"rui_SAD",	"cStruct_iBestX",	"cStruct_iBestY",	"executaTZS"]

blocksize = [cu_eixo_x, cu_eixo_y]

import pandas as pd
import gc
dataframe_treino = pd.DataFrame()
for csv in lista:
  print (csv)
  d = pd.read_csv (csv, sep=";", nrows=1000000)
  d.drop(columns=["inter_dir_normal"])
  d = d[d["cu_width"] == blocksize[0]]
  d = d[d["cu_height"] == blocksize[1]]

  n_linhas = len(d)
  if n_linhas > 10000:
    n_linhas_remover = n_linhas - 10000
    linhas_remover = d.sample(n=n_linhas_remover).index
    d = d.drop(linhas_remover)


  dataframe_treino = pd.concat([dataframe_treino, d], axis=0)
  del d
  gc.collect()

dataframe_treino

"""TESTE DA ÁRVORE DE DECISÃO"""

from os import listdir
from os import chdir
#import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn import metrics
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import accuracy_score
from collections import Counter
from imblearn.under_sampling import RandomUnderSampler

!pip install m2cgen
import m2cgen as m2c
import gc

import seaborn as sns

#função para aplicar o modelo da DT
def apply_Decision_Tree(_X_train, _y_train, _nome_arq, _save_path):

	#model_decison_tree_class = DecisionTreeClassifier(random_state = 42, max_depth = 10)

	#realiza o treinamento do modelo
	model_decison_tree_class.fit(_X_train,_y_train)

	code_DT_em_C = m2c.export_to_c(model_decison_tree_class)

  #file = open(_save_path+'DT_TZS_'+cu_eixo_x+'x'cu_eixo_y+'.cpp', 'w')
  #file = open(_save_path+'DT_TZS_'+_cu_eixo_x+'x'_cu_eixo_y+'.cpp', 'w')
	file = open(_save_path+'DT_TZS_'+_nome_arq+'.cpp', 'w')
	file.write(code_DT_em_C)
	file.close()

#caminho onde se encontram os arquivos com as features sem tratamento
#load_path_treino = dataset
#load_path_teste = dataset
save_path = "drive/My Drive/Mestrado/Dissertação/Treinamento DTs TZS/"

#lista com as features que serão utilizadas
features = [
    'qp',
    'depth',
    'qt_depht',
    'mt_depth',
    #'video_width',
    #'video_heigh',
    'cu_pos_x',
    'cu_pos_y',
    #'bcw_index',
    'imv',
    'mv_uni_l0_hor_x',
    'mv_uni_l0_ver_y',
    'mv_uni_l1_hor_x',
    'mv_uni_l1_ver_y',
    #'cost_mv_uni_l0',
    #'cost_mv_uni_l1',
    'bits_mv_uni_l0',
    'bits_mv_uni_l1',
    'mv_bi_l0_hor_x',
    'mv_bi_l0_ver_y',
    'mv_bi_l1_hor_x',
    'mv_bi_l1_ver_y',
    #'cost_bi',
    'bits_mv_bi',
    'smvd',
    'inter_dir_normal',
    'atual_QP',
    'rui_SAD',
    'cStruct_iBestX',
    'cStruct_iBestY'
    ]

y_treino = dataframe_treino.executaTZS
X_treino = dataframe_treino[features]

y_teste = dataframe_teste.executaTZS
X_teste = dataframe_teste[features]

undersample = RandomUnderSampler(sampling_strategy = 'majority', random_state = 12)

X_under, y_under = undersample.fit_resample(X_treino, y_treino)
X_t, y_t = undersample.fit_resample(X_teste, y_teste)

model_decison_tree_class = DecisionTreeClassifier(criterion = hiper_criterion, min_samples_split = hiper_min_samples_split, min_samples_leaf = hiper_min_samples_leaf, max_features = hiper_max_features, max_depth = hiper_max_depth, max_leaf_nodes = hiper_max_leaf_nodes)
model_decison_tree_class.fit(X_under, y_under)
val_predictions = model_decison_tree_class.predict(X_t)
print("Accuracy:",metrics.accuracy_score(y_t, val_predictions))
print("Precision:",metrics.precision_score(y_t, val_predictions))
print("Recall:",metrics.recall_score(y_t, val_predictions))
print("F1:",metrics.f1_score(y_t, val_predictions))

#dataframe_treino.to_csv('/content/drive/MyDrive/Mestrado/Dissertação/Treinamento DTs TZS/VTM 16.2 - Datasets Para Cada CU/dataset_tzs_'+str(cu_eixo_x)+'x'+str(cu_eixo_y)+'_train.csv', sep=',', index=False)

feat_importances = pd.DataFrame(model_decison_tree_class.feature_importances_, index = X_treino.columns, columns = ["Importance"])
feat_importances.sort_values(by = 'Importance', ascending = False, inplace = True)
feat_importances.plot(kind='bar', figsize=(12,6))

"""TREINAMENTO DA ÁRVORE DE DECISÃO"""

from os import listdir
from os import chdir
#import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn import metrics
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import accuracy_score
from collections import Counter
from imblearn.under_sampling import RandomUnderSampler

!pip install m2cgen
import m2cgen as m2c
import gc

import seaborn as sns

#função para aplicar o modelo da DT
def apply_Decision_Tree(_X_train, _y_train, _nome_arq, _save_path):

	#model_decison_tree_class = DecisionTreeClassifier(random_state = 42, max_depth = 10)

	#realiza o treinamento do modelo
	model_decison_tree_class.fit(_X_train,_y_train)

	code_DT_em_C = m2c.export_to_c(model_decison_tree_class)

  #file = open(_save_path+'DT_TZS_'+cu_eixo_x+'x'cu_eixo_y+'.cpp', 'w')
  #file = open(_save_path+'DT_TZS_'+_cu_eixo_x+'x'_cu_eixo_y+'.cpp', 'w')
	file = open(_save_path+'DT_TZS_'+_nome_arq+'.cpp', 'w')
	file.write(code_DT_em_C)
	file.close()

#caminho onde se encontram os arquivos com as features sem tratamento
#load_path_treino = dataset
#load_path_teste = dataset
save_path = "drive/My Drive/Mestrado/Dissertação/Treinamento DTs TZS/"

#lista com as features que serão utilizadas
features = [
    'qp',
    'depth',
    'qt_depht',
    'mt_depth',
    #'video_width',
    #'video_heigh',
    'cu_pos_x',
    'cu_pos_y',
    #'bcw_index',
    'imv',
    'mv_uni_l0_hor_x',
    'mv_uni_l0_ver_y',
    'mv_uni_l1_hor_x',
    'mv_uni_l1_ver_y',
    #'cost_mv_uni_l0',
    #'cost_mv_uni_l1',
    'bits_mv_uni_l0',
    'bits_mv_uni_l1',
    'mv_bi_l0_hor_x',
    'mv_bi_l0_ver_y',
    'mv_bi_l1_hor_x',
    'mv_bi_l1_ver_y',
    #'cost_bi',
    'bits_mv_bi',
    'smvd',
    'inter_dir_normal',
    'atual_QP',
    'rui_SAD',
    'cStruct_iBestX',
    'cStruct_iBestY'
    ]

dataframe_final = pd.concat([dataframe_treino, dataframe_treino], axis=0)

y_final = dataframe_final.executaTZS
X_final = dataframe_final[features]

undersample = RandomUnderSampler(sampling_strategy = 'majority', random_state = 12)

X_under, y_under = undersample.fit_resample(X_final, y_final)

model_decison_tree_class = DecisionTreeClassifier(criterion = hiper_criterion, min_samples_split = hiper_min_samples_split, min_samples_leaf = hiper_min_samples_leaf, max_features = hiper_max_features, max_depth = hiper_max_depth, max_leaf_nodes = hiper_max_leaf_nodes)
model_decison_tree_class.fit(X_under, y_under)

apply_Decision_Tree(X_under, y_under, str(cu_eixo_x)+'x'+str(cu_eixo_y), save_path)
#apply_Decision_Tree(X_under, y_under, "16x16", save_path)
